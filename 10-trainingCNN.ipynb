{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49530747",
   "metadata": {},
   "source": [
    "# Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b48e5276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.2.1\n",
      "pytorch_lightning: 2.5.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "print('torch:', torch.__version__)\n",
    "print('pytorch_lightning:', pl.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871f0277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# 2. Reproducibility - Setting seeds ensures experiments are consistent and results are easier to compare.\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    pl.seed_everything(seed)\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc54fe",
   "metadata": {},
   "source": [
    "### DataModule\n",
    "A `LightningDataModule` organizes data loading. We use simple augmentations for training and basic normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6343be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir='~/Downloads/dataset/', batch_size=128, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform_train = T.Compose([\n",
    "            T.RandomCrop(32, padding=4),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "        ])\n",
    "\n",
    "        self.transform_val = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # downloads\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = CIFAR10(self.data_dir, train=True, transform=self.transform_train)\n",
    "        self.val_dataset = CIFAR10(self.data_dir, train=False, transform=self.transform_val)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca6c66d",
   "metadata": {},
   "source": [
    "### Model (simple CNN) and weight initialization\n",
    "We define a straightforward CNN and apply initialization using `apply()` inside the model's `__init__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e08679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*8*8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        # apply weight initialization\n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def81c86",
   "metadata": {},
   "source": [
    "Contains training/validation logic, optimizer, and scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "723bbedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCIFAR(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-3, weight_decay=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SimpleCNN(num_classes=10)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234dd4e",
   "metadata": {},
   "source": [
    "### Training\n",
    "Create datamodule, logger, checkpoint callback, and Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5322f2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | SimpleCNN        | 545 K  | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "545 K     Trainable params\n",
      "0         Non-trainable params\n",
      "545 K     Total params\n",
      "2.180     Total estimated model params size (MB)\n",
      "14        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oarif/Documents/workspace/COE49413/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n",
      "/Users/oarif/Documents/workspace/COE49413/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:428: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02841a861594b16bbf96e1edd3e793f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "# Config for a lightweight demo suitable for students\n",
    "cfg = Namespace(\n",
    "    data_dir='~/Downloads/dataset/',\n",
    "    batch_size=256,\n",
    "    max_epochs=2,   # set small for quick demo; increase for real training\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "dm = CIFAR10DataModule(data_dir=cfg.data_dir, batch_size=cfg.batch_size)\n",
    "model = LitCIFAR(lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "csv_logger = CSVLogger(\".logs\", name=\"cifar10\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=cfg.max_epochs,\n",
    "    logger=csv_logger,\n",
    "    log_every_n_steps=100,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=dm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3f3f12-2eee-4c9e-96df-b54cec023995",
   "metadata": {},
   "source": [
    "# Exercise: \n",
    "Try different initialization, regularization (dropout, l2 regularization), and see the effect on the training and validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d4bc89e-1dcf-454f-8f16-946ab4813380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_zero(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        torch.nn.init.zeros_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "        #m.weight.data.fill_(0)\n",
    "        #m.bias.data.fill_(0)\n",
    "\n",
    "def weights_init_random(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        torch.nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        torch.nn.init.normal_(m.bias, mean=0, std=0.01)\n",
    "        #m.weight.data.fill_(0)\n",
    "        #m.bias.data.fill_(0)\n",
    "\n",
    "def weights_init_xavier(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def weights_init_kaiming(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(m.weight.data)\n",
    "        m.bias.data.fill_(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa1440-156f-4fc8-a11b-6df1002d81ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
